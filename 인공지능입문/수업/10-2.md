# 최근접 이웃 회귀
## 새롭게 들어온 의뢰
한빛 마켓에서 농어를 무게 단위로 판매하려고 한다.

농어의 길이, 높이, 두께 정보를 이용해 무게를 자동으로 예측할 수 있을까?

## 회귀(Regression)
지도 학습의 한 종류이다.

몇 개의 클래스 중 하나를 선택하는 분류(classification) 문제와 다르게, 임의의 어떤 숫자 예측을 목표한다.

회귀 문제의 예시는 아래와 같다.
- 경제 성장률을 예측한다.
- 배달이 도착할 시간을 예측한다.

농어 무게 예측도 회귀이다.

## K - 최근접 이웃 회귀
앞서 다루었던 k - 최근접 이웃 분류의 회귀 버전은 아래와 같다.

<img width="495" alt="image" src="https://github.com/user-attachments/assets/fdd2b859-df74-45fd-9687-97c3bae8b6dd">

## 데이터 준비
농어의 길이와 무게 데이터를 넘파이 배열로 로드한다.
- https://bit.ly/perch.data 에서 복사하여 사용한다.

```
import numpy as np

perch_length = np.array([8.4, 13.7, 15.0, 16.2, 17.4, 18.0, 18.7, 19.0, 19.6, 20.0, 21.0,
       21.0, 21.0, 21.3, 22.0, 22.0, 22.0, 22.0, 22.0, 22.5, 22.5, 22.7,
       23.0, 23.5, 24.0, 24.0, 24.6, 25.0, 25.6, 26.5, 27.3, 27.5, 27.5,
       27.5, 28.0, 28.7, 30.0, 32.8, 34.5, 35.0, 36.5, 36.0, 37.0, 37.0,
       39.0, 39.0, 39.0, 40.0, 40.0, 40.0, 40.0, 42.0, 43.0, 43.0, 43.5,
       44.0])
perch_weight = np.array([5.9, 32.0, 40.0, 51.5, 70.0, 100.0, 78.0, 80.0, 85.0, 85.0, 110.0,
       115.0, 125.0, 130.0, 120.0, 120.0, 130.0, 135.0, 110.0, 130.0,
       150.0, 145.0, 150.0, 170.0, 225.0, 145.0, 188.0, 180.0, 197.0,
       218.0, 300.0, 260.0, 265.0, 250.0, 250.0, 300.0, 320.0, 514.0,
       556.0, 840.0, 685.0, 700.0, 700.0, 690.0, 900.0, 650.0, 820.0,
       850.0, 900.0, 1015.0, 820.0, 1100.0, 1000.0, 1100.0, 1000.0,
       1000.0])
```

## 길이를 사용한 무게 예측
입력 특성으로 사용할 수 있는 것은 3개가 있지만, 길이만 사용해보자.

산점도로 입력(길이) - 출력(무게) 관계를 시각화한다.

```
import matplotlib.pyplot as plt

plt.scatter(perch_length, perch_weight)
plt.xlabel('length')
plt.ylabel('weight')
plt.show()
```

<img width="586" alt="image" src="https://github.com/user-attachments/assets/957210fb-2b9e-40a9-b024-741cb072e0f1">

- 농어의 길이 특성이 커짐에 따라 무게가 늘어나는 패턴이 관측된다.

## 훈련 및 테스트 세트 분할
훈련 세트는 2차원 데이터로 표현되어야 한다.
- (샘플 수, 특성 수)

하나의 특성(길이)만 사용하여 일차원 데이터로 표현될 수 있다.
- (샘플 수, )
  - 사이킷런 포멧에 맞춰주어야 한다.
 
넘파이의 `reshape()`를 사용한다.

`model_selection` 모듈의 `train_test_split()`을 사용한다.

```
from sklearn.model_selection import train_test_split
```

길이(perch_length)와 무게(perch_weight)를 각각 입, 출력 인자로 전달한다.

```
train_input, test_input, train_target, test_target = train_test_split(perch_length, perch_weight, random_state=42)
```

분할된 데이터의 형상을 확인한다.

```
print(train_input.shape, test_input.shape)

"""
결과
(42,) (14,)
"""
```

분할된 데이터가 뭔가 문제가 있다.

배열의 형상을 원하는 형태로 만드는 넘파이 `reshape()`를 사용한다.

결과 배열의 형상은 원본 배열과 같은 데이터 수를 가져야 한다.

훈련 셋, 테스트 셋의 샘플 수는 설정값에 따라 달라질 수 있으니 샘플 수를 지정하지 않고 -1을 사용하는 것이 적절하다.

```
from sklearn.model_selection import train_test_split

train_input, test_input, train_target, test_target = train_test_split(perch_length, perch_weight, random_state=42)

train_input = train_input.reshape(-1, 1)
test_input = test_input.reshape(-1, 1)
```

<img width="241" alt="image" src="https://github.com/user-attachments/assets/b95b1adb-53d7-4748-90d9-7b348722a7ef">

## 회귀 모델 훈련
`sklearn.neighbors`의 `KNeighborsRegressor` 클래스를 사용한다.

```
from sklearn.neighbors import KNeighborsRegressor
```

`fit()` 메소드로 훈련한다.

```
knr = KNeighborsRegressor()
knr.fit(train_input, train_target)
```

`score()` 메소드로 테스트 세트에 대한 성능 점수를 확인한다.

```
knr.score(test_input, test_target)

"""
결과
0.992809406101064
"""
```

점수의 의미는 무엇일까?

## 회귀 모델의 평가 : 결정 계수
분류 모델의 성능 측정을 위해 정확도(정확하게 분류한 샘플의 비율)를 사용했다.

회귀 모델의 성능 측정을 위해서 결정 계수(coefficient of determination, R - squared)를 사용한다.
- 최대값은 1이다.

<img width="259" alt="image" src="https://github.com/user-attachments/assets/cc67adb9-c2a8-4815-a5f5-2846bc671196">

두 지표 모두 사이킷런 모델의 `score()` 메소드로 측정 가능하다. (객채 지향 구현)

## 회귀 모델의 평가 : 절대값 오차
결정 계수는 값의 의미를 직관적으로 파악하기 어렵다.

회귀 모델의 평가를 위해서 다른 지표들도 활용 가능하며, `sklearn.metrics` 모듈에서 다양한 지표 측정을 위한 함수를 제공한다.

절대값 오차(mean absolute error, MAE)를 사용해 회귀 모델 성능을 측정해보자.

<img width="241" alt="image" src="https://github.com/user-attachments/assets/c9ad0a5c-587e-4191-9506-056cf32e7bd2">

- MAE는 예측값과 정답값의 차이(오차) 평균이다.

```
from sklearn.metrics import mean_absolute_error

test_prediction = knr.predict(test_input)

mae = mean_absolute_error(test_target, test_prediction)
print(mae)

"""
결과
19.157142857142862
"""
```

- 무게 예측이 평균적으로 19g 정도 틀린다고 해석할 수 있다.

## 과대적합과 과소적합
훈련 데이터에 대해 성능을 측정해보자.

```
print(knr.score(train_input, train_target))

knr.score(test_input, test_target)

"""
결과
0.9698823289099254

0.992809406101064
"""
```

- 훈련 데이터에 대해서만 훈련했지만, 오히려 낮은 성능이 관측되었다.

### 과소적합(Underfitting)
훈련 세트에 대해 낮은 성능이 관측되거나 테스트 세트 성능에 비해 훈련 세트 성능이 낮은 경우를 말한다.

모델이 데이터 패턴을 학습하기에 충분히 복잡하지 않은 경우 과소적합이 발생할 수 있다.

위 모델은 과소적합 모델이다.

### 과대적합(Overfitting)
과소적합과 반대로, 훈련 세트에 대해서 성능이 높지만 테스트 세트에서 성능이 낮아지는 경우를 말한다.

## 과소적합 해결하기
모델 과소적합 문제를 어떻게 해결할 수 있을까?

과소적합은 모델이 훈련 세트의 특징을 잘 잡지 못해서 발생한다.
- 더 복잡한 알고리즘을 사용한다.
- 같은 알고리즘의 설정값을 바꾸어 훈련 세트의 패턴을 더 잘 잡을 수 있게 만든다.

k - 최근접 이웃 알고리즘의 경우, 참조하는 이웃의 수(k값)를 줄여서 훈련 세트의 패턴에 더 민감하게 만들 수 있다.
- 모델을 더 복잡하게 할 수 있다.

<img width="661" alt="image" src="https://github.com/user-attachments/assets/7a04aedc-e9d3-4243-8c33-8d2c8e407161">

n_neighbors 파라미터를 바꾸어 모델을 다시 훈련한다.

```
# 이웃의 개수를 3으로 설정한다.
knr.n_neighbors = 3

knr.fit(train_input, train_target)

print(knr.score(train_input, train_target))

print(knr.score(test_input, test_target))

"""
결과
0.9804899950518966

0.9746459963987609
"""
```

- 훈련 셋 성능이 높아졌을 뿐 아니라, 테스트 셋 성능과의 차이는 크지 않다.
- 절대적인 테스트 셋 성능은 기존 모델이 높지만, 훈련 셋 성능이 높고 테스트 셋 성능이 비슷하거나 약간 낮아지는 형태로 만드는 것이 이상적이다.
  - 일반화가 잘 될 것으로 예상할 수 있다.
 
## 마무리
### 키워드로 끝내는 핵심 포인트
#### 회귀(Regression)
임의의 수치를 예측하는 문제로, 타깃값도 임의의 수치가 된다.

#### K - 최근접 이웃 회귀
가장 가까운 이웃 샘플을 찾고, 샘플들의 타깃값을 평균하여 예측한다.

#### 결정계수(R - Squared)
회귀 모델의 성능 측정 도구이다.

최대값은 1이고, 이보다 작아질수록 더 좋지 않은 성능을 의미한다.

#### 과대적합(Overfitting)
훈련 세트 성능이 테스트 세트 성능보다 높을 때를 의미한다.

모델이 훈련 세트의 패턴에 너무 집중하여, 일반화 성능이 낮아진다.

#### 과소적합(Underfitting)
훈련 세트와 테스트 세트 성능이 동일하게 낮거나, 테스트 성능이 오히려 높을 때를 의미한다.

더 복잡한 모델을 사용해 훈련 세트에 잘 맞는 모델을 만들어야 한다.

### 핵심 패키지와 함수
#### scikit - learn
`KNeighborsRegressor`
- k - 최근접 이웃 회귀 모델을 만드는 사이킷런 클래스이다.
- n_neighbors 매개변수로 이웃의 개수를 지정하며, 기본값의 5이다.

`mean_absolute_error()`
- 회귀 모델의 평균 절대값 오차를 계산한다.
- 첫 번째 매개변수는 타깃, 두 번째 매개변수는 예측값을 전달한다.
- 이와 비슷한 함수로 평균 제곱 오차를 계산하는 `mean_squared_error()`가 있다.

#### numpy
`reshape()`
- 배열의 크기를 바꾸는 메소드로, 바꾸고자 하는 배열의 크기를 인자로 전달한다.

## 확인 문제
### 1번
k - 최근접 이웃 회귀에서는 새로운 샘플에 대한 예측을 어떻게 만드는가?

1. 이웃 샘플 클래스 중 다수인 클래스
2. 이웃 샘플의 타깃값의 평균
3. 이웃 샘플 중 가장 높은 타깃값
4. 이웃 샘플 중 가장 낮은 타깃값

### 2번
과대적합과 과소적합에 대해 이해하기 위해, 복잡한 모델과 반순한 모델을 만들어보자.

앞서 만든 k - 최근접 이웃 회귀 모델의 k값을 1, 5, 10으로 바꿔가며 훈련해보고, 농어의 길이를 5에서 45까지 바꾸어 가며 예측을 만들어 그래프로 나타내자.

```
knr = KNeighborsRegressor()

# 5에서 45까지 x 좌표를 만든다.
x = np.arange(5, 45).reshape(-1, 1)

# n = 1, 5, 10일 때 예측 결과를 그래프로 그린다.
for n in [1, 5, 10]:
  # 모델 훈련
  knr.n_neighbors = n
  knr.fit(train_input, train_target)

  # 지정한 범위 x에 대한 예측 구하기
  prediction = knr.predict(x)

  # 훈련 세트와 예측 결과 그래프 그리기
  plt.scatter(train_input, train_target)
  plt.plot(x, prediction)
  plt.title('n_neighbors = {}'.format(n))
  plt.xlabel('length')
  plt.ylabel('weight')
  plt.show()
```

<img width="576" alt="image" src="https://github.com/user-attachments/assets/91048671-c966-4a93-8abc-98631072ae6f">

<br>

<img width="582" alt="image" src="https://github.com/user-attachments/assets/cefdf0dc-5b28-4fd8-bbf7-e7ceb1bb0b87">

<br>

<img width="578" alt="image" src="https://github.com/user-attachments/assets/0a919916-873e-4c09-9e94-1ed1d2f99fbe">
