# 로지스틱 회귀 2
## 분류의 종류
### 이진 분류(Binary Classification)
두 개의 클래스(예 / 아니요, 0 / 1, 참 / 거짓)로 데이터를 분류하는 작업이다.

메일을 스팸과 정상 메일로 분류하거나, 환자가 특정 질병을 앓고 있는지 여부를 판별하는 경우이다.

이진 분류 문제에서는 주로 로지스틱 회귀, 서포트 벡터 머신(SVM), 신경망 등의 알고리즘이 사용된다.

### 다중 클래스 분류(Multiclass Classification)
상호 베타적인 여러 클래스 중 하나로 데이터를 분류하는 작업이다.

동물 이미지를 고양이, 개, 새 등의 여러 종류로 분류하거나, 색상을 빨강, 파랑, 노랑 등의 여러 색상으로 분류하는 경우이다.

다중 클래스 분류 문제에서는 소프트맥스 회귀, 결정 트리, 랜덤 포레스트, 신경망 등의 알고리즘이 사용된다.

### 다중 레이블 분류(Multilabel Classification)
하나의 데이터에 여러 개의 레이블을 할당하는 작업이다.

데이터가 동시에 여러 카테고리에 속할 수 있음을 의미한다.

게시물에 여러 태그를 붙이거나, 영화에 여러 장르를 할당하는 경우이다.

노드가 특정 클래스에 대한 확률을 출력하도록 하는 접근 방식이 사용된다.

## 다중 클래스 분류와 소프트맥스 분류
### 다중 클래스 분류(Multi - Class Classification)
2개 이상의 클래스를 가진 y 값에 대한 분류이다.
- 다중 클래스와 다중 레이블은 아래와 같은 차이를 가진다.

<img width="1133" alt="image" src="https://github.com/user-attachments/assets/0e42543a-532a-4fd9-b8f2-769ed2fbb6bf">

## 다중 클래스 분류 접근법
### One - vs - All(One - vs - Rest)
m개의 클래스가 존재할 때 각 클래스마다 (이진) 분류기(classifier)를 생성하여 분류한다.

대표적으로 소프트맥스 분류(softmax classification)를 들 수 있다.

<img width="633" alt="image" src="https://github.com/user-attachments/assets/2c088130-970a-4a33-804c-e510a6076cf2">

### One - vs - One
m개의 클래스가 있다면, 이 클래스의 분류기를 하나의 클래스로 하고 나머지 클래스의 분류기들을 만들어 최종적으로 각 분류기들의 결과를 투표로 결정한다.

총 m(m - 1) / 2개만큼의 분류기를 생성한다.(조합)

분류기가 많아질수록 정확도가 높아지지만 비용도 증가한다.

<img width="524" alt="image" src="https://github.com/user-attachments/assets/ccdbfd67-72fd-4946-8c65-61fd16a1491b">

## 소프트맥스 함수
다중클래스 분류 문제를 다룰 수 있는 시그모이드 함수이다.

각각의 클래스에 속하는지 속하지 않는지 이진분류기 m개를 생성한 후, 가장 높은 확률이 나오는 클래스를 선택한다.

분류기 번호 m에 대해 h<sub>m</sub>(x;θ)로 표현한다.

그러나 h<sub>m</sub>(x;θ)의 합이 1 이상이 된다는 문제가 발생하므로, 모든 클래스들의 발생 확률을 1로 정규화 해준다.

### 소프트맥스 함수(Softmax Function)
다중클래스 분류에서 여러 회귀의 출력 결과를 정규화하여 합이 1이 되도록 만드는 함수이다.

<img width="827" alt="image" src="https://github.com/user-attachments/assets/35b46054-f517-408c-8c88-41f0e7e5f46f">

## 소프트맥스 분류?
소프트맥스 함수를 생각해보자.
- 이진 분류의 로지스틱 회귀에 오즈비에 logit 함수를 붙여 최종적으로 구한 가중치 값은 아래와 같다.

<img width="652" alt="image" src="https://github.com/user-attachments/assets/64ec5638-ed83-4bad-a2f7-5e620a379db8">

- 이것은 이진 분류에 해당하는 값이다.
  - 다중 분류는 클래스가 더 많아진다.
 
- logit 함수는 아래와 같다.

<img width="340" alt="image" src="https://github.com/user-attachments/assets/2277bcdc-94e3-4452-9fa1-feee7fd8a83a">

## 오즈의 의미?
(1 - p)란 true가 아닐 확률 즉, false일 확률을 의미한다.
- 일반화하면 아래와 같다.

<img width="275" alt="image" src="https://github.com/user-attachments/assets/15bac9e7-0b09-4e83-a2a3-66795751a30f">

- 여기에서 C<sub>1</sub>과 C<sub>1</sub>는 가질 수 있는 2개의 클래스이다.

## 소프트맥스 분류?
로지스틱 회귀를 일반화해서 다중 로지스틱 회귀와 가장 다른 점은 j개의 클래스가 있다면, 각 클래스마다 가중치 벡터가 존재한다는 점이다.
- 총 k개의 샘플이 있다 가정할 때, k번째 클래스의 확률과 j번째 클래스 확률의 비를 아래와 같이 쓸 수 있다.

<img width="347" alt="image" src="https://github.com/user-attachments/assets/1c26629e-d9d1-4910-b57b-d5cd65e40405">

- 양 변을 i = 1부터 (K - 1)까지 더한다.

<img width="576" alt="image" src="https://github.com/user-attachments/assets/0b074e17-1eee-4584-adab-c74507b3a8fc">

- 가장 오른쪽 두 항의 분모와 분자를 뒤집어서 정리한다.

<img width="303" alt="image" src="https://github.com/user-attachments/assets/498a9141-49c0-4ea1-bddf-522c93131a5a">

- 맨 첫번째 식에서 아래의 관계를 유도할 수 있다.

<img width="440" alt="image" src="https://github.com/user-attachments/assets/9c9e4bc5-b7df-45a9-9e64-2b556a428d7f">

- 이제 위 두 식을 합치면 소프트맥스 함수가 나온다.

<img width="832" alt="image" src="https://github.com/user-attachments/assets/6ec12049-bccc-4562-944e-d35de1c2c8d7">

- 즉, 아래의 관계식을 얻을 수 있다.

<img width="483" alt="image" src="https://github.com/user-attachments/assets/0d983ba2-aac9-4a2b-ad15-ab6b250cfdfc">

## 학습은 어떻게 하면 될까?
아래 수식에서 θ를 학습한다.

<img width="465" alt="image" src="https://github.com/user-attachments/assets/35a9dfd9-94a9-4612-8065-1623bef21f06">

즉, 각 클래스마다 적절한 θ<sub>j</sub>를 찾는다.
- 각 가설함수는 각 클래스와 발생확률로 표현이 가능하다.

<img width="633" alt="image" src="https://github.com/user-attachments/assets/347f1c58-50af-4958-9406-1ed5a092b64a">

최대우도추정법(Maximum Likelihood Estimation, MLE)을 사용해서 확률을 최대화하는 θ를 찾는다.

<img width="401" alt="image" src="https://github.com/user-attachments/assets/86a8b2f9-042e-44e3-96c7-11dc7e0e14e0">

위 수식을 손실(loss)로 생각하여 수식 L로 표현하고 해당 값을 최대화하는 방향으로 정리한다.

## Maximum Likelihood Estimation Remind
likelihodo function이라는 것을 아래와 같이 정의하자.
- L(x<sub>1</sub>, ..., x<sub>n</sub>, θ) = f(x<sub>1</sub>, θ) x ... x f(x<sub>n</sub>, θ)
- f(x, θ)는 임의의 확률 밀도 함수라고 생각해보자.
- x<sub>1</sub>, ..., x<sub>n</sub>은 f(x, θ)에서 샘플링한 데이터셋이라고 생각해보자.
- θ는 우리가 아직 알지 못하는 미지의 parameter이다.

최대우도추정(maximum likelihood estimation, MLE)는 위의 L 값을 최대화 시키는 point estimate θ를 찾아내서 point estimate를 추정하는 것이다.

parameter가 여러 개면 f(x<sub>i</sub>, θ) -> f(x<sub>i</sub>, θ<sub>1</sub>, θ<sub>2</sub>)이다.

log - likelihood
- log[L(x<sub>1</sub>, ..., x<sub>n</sub>, θ] = log(f(x<sub>1</sub>, θ)) + ... + log(f(x<sub>n</sub>, θ))
- f(x<sub>i</sub>, θ)인 경우, f(x)를 최대화하는 X와 log(f(x))를 최대화하는 X는 같다.

## 학습은 어떻게 하면 될까?
위 수식을 손실(loss)로 생각하여 수식 L로 표현하고 해당 값을 최대화하는 방향으로 정리한다.

<img width="1097" alt="image" src="https://github.com/user-attachments/assets/b1e75d24-4d04-45b0-ac4f-f5b158005717">

## Cross Entropy and Information Theory
실제 분포 p와 추정된 분포의 차이는 아래와 같이 cross entropy라는 개념으로 둘 수 있다.

<img width="439" alt="image" src="https://github.com/user-attachments/assets/cb2f21ce-46e9-4b35-9db7-188de9ad8371">

이는 앞에서 구한 I 값의 형태와 일치한다.

즉, 이 loss는 cross entropy를 최적화하는 것과 거의 같다.

## MNIST 데이터셋
손글씨를 숫자로 인식하는 이미지 분류 문제이다.

<img width="469" alt="image" src="https://github.com/user-attachments/assets/17c75e98-69ac-488e-922b-17900eabb849">

컴퓨터는 이미지를 일종의 숫자로 변환하여 인식한다.
- 이미지를 일종의 점(dot)으로 생각하면 m x n만큼의 공간이 존재하고, 그 공간 안에서 색깔이 진할수록 높은 값, 색깔이 옅을수록 낮은 값을 갖는다.

## ROC 커브와 AUC
정밀도와 민감도는 트레이드오프이다.
- 정밀도(precision)와 민감도(recall)는 일반적으로 둘 다 동시에 상승하기 어렵고 임계값(threshold)에 따라 변화가 일어난다.
  - 두 값을 모두 고려하여 성능을 측정하기 쉽지 않다.
 
- ROC 커브(ROC curve)는 분류기의 임계값을 지속적으로 조정하여 정밀도와 민감도 간의 비율을 보여준다.
  - 'Receiver Operating Charactesrisitcs'의 약자이다.
  - 클래스의 예측 확률이 나오는 모델에 사용이 가능하다.
 
<img width="842" alt="image" src="https://github.com/user-attachments/assets/1ca90234-8294-4aa5-9bc3-5788970499df">

## ROC 커브 표현하기
TPR(True Positive Rate)과 FPR(False Positive Rate)을 각각 y축, x축에 나타내어 그래프를 작성한다.

<img width="1135" alt="image" src="https://github.com/user-attachments/assets/fad05a07-6908-4dba-bd99-dba1d9c7957e">

## ROC 커브와 AUC

<img width="791" alt="image" src="https://github.com/user-attachments/assets/d1eca447-5617-4ef1-954d-bb417f485045">

TPR과 FPR의 값을 연결하여 그래프를 작성한다.

<img width="348" alt="image" src="https://github.com/user-attachments/assets/cafa2af7-8c8b-49da-a494-e6b59e9bef6a">

AUC(Area Under Curve)는 ROC 커브 하단의 넓이이다.

모델들의 성능을 단 하나의 숫자로 표현할 수 있다는 점에서 불균형 데이터셋(imbalanced dataset)의 성능을 평가할 때 많이 사용한다.

<img width="417" alt="image" src="https://github.com/user-attachments/assets/275a4a28-ac69-4478-ba95-5e1c6c3edccd">

## Micro Average & Macro Average
### Macro Average
각 클래스별로 지표를 계산한 후 평균을 낸다.

모든 클래스에 동일한 가중치를 부여한다.

클래스 불균형이 있을 때도 각 클래스를 동등하게 취급한다.

(클래스1_지표 + 클래스2_지표 + ... + 클래스N_지표) / N

### Micro Average
전체 데이터에 대해 한 번에 지표를 계산한다.

각 샘플에 동일한 가중치를 부여한다.

클래스 불균형이 있을 때 더 많은 샘플을 가진 클래스에 높은 가중치를 부여한다.

데이터를 하나로 모아서 계산하므로 클래스 크기의 영향을 받는다.

### 클래스가 균형적일 때
Macro와 Micro average가 비슷한 값을 보인다.
- 어떤 것을 사용해도 무방하다.

MNIST가 이런 케이스이다.

### 클래스가 불균형할 때
Macro average는 소수 클래스의 성능도 중요할 때 사용한다.
- 각 "클래스"가 동일한 중요도를 가진다.

Micro average는 다수 클래스의 성능이 중요할 때 사용한다.
- 각 "샘플"이 동일한 중요도를 가진다.
