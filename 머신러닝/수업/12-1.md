# 나이브 베이지안 분류기
## 확률의 표현
이산(discrete)형 값의 확률은 아래와 같다.

<img width="206" alt="image" src="https://github.com/user-attachments/assets/3c327f16-9052-4706-b024-c73ac8552b2f">

<br/>

<img width="351" alt="image" src="https://github.com/user-attachments/assets/c27f61bf-f51e-47a1-896a-437f7b3595d0">

연속형 값의 확률은 해당 데이터를 적절히 표현하는 함수를 생성한 후 해당 함수의 적분 값을 취한다.
- 특정 위치의 값을 정의하기 어렵고 적분 값을 취해 구간의 확률을 계산한다.

<img width="406" alt="image" src="https://github.com/user-attachments/assets/702f7074-d8fc-406f-a93d-60e61da297e8">

## 확률의 기본 성질
확률은 모든 사건에 대해 반드시 0에서 1 사이의 값을 가짐
- 0 <= P(X) <= 1

각 사건들이 서로 관계가 없는 경우, 즉 사건들이 일어날 확률이 다른 사건이 일어날 확률에 영향을 미치지 않을 때 각 사건들이 '독립'되었다고 정의한다.

<img width="192" alt="image" src="https://github.com/user-attachments/assets/0e025cca-d651-4bab-8428-622727b5b8ed">

## 조건부 확률
특정 사건이 일어난 것을 알고 있을 때, 다른 사건이 동시에 발생하는 확률이다.
- P(A | B) = P(A ⋂ B) / P(B)
- ex)
  - A = {x | x는 홀수}, B = {x | x는 4보다 작은 수}

A ⋂ B = ∅ 일 때
- P(A | B) = P(A ⋂ B) / P(B) = 0 / P(B) = 0

A ⋂ B = B 일 때
- P(A | B) = P(A ⋂ B) / P(B) = P(B) / P(B) = 1

### 예

<img width="309" alt="image" src="https://github.com/user-attachments/assets/14568e69-4a23-4d26-8a3e-8677bb779694">

- P(A | B) = P(A ⋂ B) / P(B) = 0.26 / 0.56 = 0.464
- P(A | B') = P(A ⋂ B') / P(B') = (P(A) - P(A ⋂ B)) / (1 - P(B)) = (0.27 - 0.26) / (1 - 0.56) = 0.023

## 예 : 주사위 던지기
주사위가 짝수일 때 6일 확률
- P(6) = 1 / 6
- P(6 | even) = P(6 ⋂ even) / P(even) = P(6) / P(even) = P(6) / (P(2) + P(4) + P(6)) = 1 / 3

A = {the red dice scores at 6}

B = {at least one 6 is obtained on the two dice}
- P(A) = 6 / 36 = 1 / 6 and P(B) = 11 / 36
- P(A | B) = P(A ⋂ B) / P(B) = P(A) / P(B) = 6 / 11

<img width="332" alt="image" src="https://github.com/user-attachments/assets/230d0ac4-adb4-4337-9937-90bc399a0690">

C = {exactly one 6 has been scored}
- P(A | C) = P(A ⋂ C) = P(C) = 1 / 2

<img width="340" alt="image" src="https://github.com/user-attachments/assets/d9825113-3ea4-4069-bf25-296fb289fe3a">

## 독립 사건(Independent Events)
P(B | A) = P(B)
- P(A ⋂ B) = P(A)P(B | A) = P(A)P(B)

P(A | B) = P(A ⋂ B) / P(B) = P(A)P(B) / P(B) = P(A)
- 즉 독립 사건은 상호적이다.(일방적이지 않다.)

위의 사실에서 알 수 있듯, 아래 중 한 가지라도 성립하면 사건 A와 B는 서로 독립 사건이라고 한다.
- P(A | B) = P(A), P(B | A) = P(B), P(A ⋂ B) = P(A)P(B)
- 위의 것 중 한가지라도 성립하면 나머지도 성립한다.

독립사건은 한 사건이 발생한 사실을 아는 것이 다른 사건의 확률에 아무 영향을 주지 못한다는 뜻이다.

독립 사건 A<sub>1</sub>, A<sub>2</sub>, ..., A<sub>n</sub>은 아래의 성질을 만족한다.
- P(A<sub>1</sub> ⋂ ... ⋂ A<sub>n</sub>) = P(A<sub>1</sub>)P(A<sub>2</sub>)...P(A<sub>n</sub>)

## 베이즈 정리(Bayes' Theorem)
두 확률 변수의 사전확률(prior probability)과 사후확률(posterior probabily) 사이의 관계를 나타내는 정리이다.
- 사전확률
  - 어떤 이벤트가 일어나기 전에 그 이벤트가 일어날 확률이다.
 
- 사후확률
  - 새로운 정보가 주어진 후에, 특정 이벤트가 일어날 확률이다.
 
베이즈정리의 전제는 아래와 같다.
- 객관적인 확률이 존재하지 않고 이전 사건으로 인해 확률이 지속적으로 업데이트된다.

## 베이즈주의와 빈도주의

<img width="288" alt="image" src="https://github.com/user-attachments/assets/066256f3-76a4-4f45-ba53-6a5a448ac860">

베이즈주의자는 실제로 뒤집어 카드가 나온 확률을 기반으로 실행할 때마다 계속하여 확률을 업데이트한다.

빈도주의자는 다음 확률을 계속하여 실행할 경우 1 / 3 에 수렴할 것이므로 1 / 3 로 간주한다.

<img width="403" alt="image" src="https://github.com/user-attachments/assets/a31257e7-588b-49b9-ac6a-6267b5cff0e6">

## 베이즈 정리의 이해
H는 가설, D는 데이터일 때 P(H | D)는 사후확률이다.
- P(H | D) = P(H)P(D | H) / P(D)

사후확률은 데이터가 주어졌을 때 해당 가설이 맞는지에 대한 확률이다.

가능도(likelihood)는 어떤 사건이 발생했을 때 다음 사건이 발생할 수 있는 모든 확률의 발생가능한 정도를 확률로 나타낸 것이다.
- P(D | H)는 가설이 주어졌을 때 해당 데이터가 존재할 확률이다.

<img width="466" alt="image" src="https://github.com/user-attachments/assets/14ac70e7-e1a4-48bc-8912-c31cdc0229db">

<br/>

<img width="477" alt="image" src="https://github.com/user-attachments/assets/dfcad1b7-c373-446b-a302-8296b79bc526">

## 또 다른 문제 : 몬티홀 문제

<img width="573" alt="image" src="https://github.com/user-attachments/assets/6b0cb300-72b3-4b17-8f39-479e50784013">

<br/>

<img width="302" alt="image" src="https://github.com/user-attachments/assets/d4df56b5-c4ab-4e09-a94f-43883e17232c">

<br/>

<img width="588" alt="image" src="https://github.com/user-attachments/assets/1d3bca8d-a710-479a-bdc9-30ddb21e9468">

## 가장 간단한 베이즈 분류기
### 베이즈 분류기 만들기
메일에 비아그라(viagra)라는 단어가 들어가면 어느 정도의 확률로 스팸메일인지 판단하는 분류기를 만들어보자.
- P(spam | viagra) = P(spam)P(viagra | spam) / P(viagra)

<img width="413" alt="image" src="https://github.com/user-attachments/assets/6fd11b8c-934f-4098-b1a6-81d116ccc4ff">

S : Spam, V : Viagra 일 때
- P(V) = 6 / 20, P(S) = 6 / 20
- P(S | V) = P(S)P(V | S) / P(V) = 0.5
- P(S | ~V) = P(S)P(~V | S) / P(~V) = 0.2142...

viagra라는 단어가 포함되었을 때 스팸메일일 확률(0.5)은 viagra라는 단어가 포함되지 않았을 때 스팸메일일 확률(0.2142...)보다 높다.

viagra라는 단어가 있으면 스팸메일로 분류하는 것이 합리적이다.
- 하지만 viagra라는 단어 외에 영향을 주는 단어가 있을 수 있다.
- 오히려 스팸에서 제외되는 메일에 viagra라는 단어가 있을 수 있다.

나이브 베이지안 분류기가 위 문제점을 해결할 수 있다.

## 교사건의 확률
P(A | B) = P(A ⋂ B) / P(B), P(B | A) = P(A ⋂ B) / P(A)
- P(A ⋂ B) = P(B)P(A | B) = P(A)P(B | A)

P(C | A ⋂ B) = P(A ⋂ B ⋂ C) / P(A ⋂ B)
- P(A ⋂ B ⋂ C) = P(A ⋂ B)P(C | A ⋂ B) = P(A)P(B | A)P(C | A ⋂ B)
- 그래서 변수가 많아지면 구해야할 값들이 점점 복잡해진다.

## 해결방법 : 나이브 베이지안
데이터의 특징을 가지고 각 클래스(레이블)에 속할 확률을 계산하는 조건부 확률 기반의 분류 방법이다.

데이터의 특징이 모두 상호 독립적이라는 가정하에 확률 계산을 단순화한다.
- 나이브(naive)하다.

베이즈 정리에 의해 데이터의 특징을 통해 클래스 전체의 확률 분포 대비 특정 클래스에 속할 확률을 구하는 것이다.

독립사건을 가정하면 아래와 같이 단순화할 수 있다.
- P(A | X ⋂ Y) = P(X ⋂ Y | A)P(A) / P(X ⋂ Y) = P(X | A)P(Y | A)P(A) / P(X)P(Y)

일반화하면 아래와 같다.

<img width="289" alt="image" src="https://github.com/user-attachments/assets/08da7fd2-b2ea-4543-8598-eb606440898e">

## 예
광고, SNS, 결제라는 키워드를 가지면 스팸일 확률을 구해보자.

단 메일이 광고, SNS, 결제라는 키워드를 가지는 사건은 서로 독립이다.
- P(SPAM | AD, SNS, PAY) = P(AD | SPAM)P(SNS | SPAM)P(PAY | SPAM)P(SPAM) / P(AD)P(SNS)P(PAY)

하지만 이는 현실과 다르다.

이게 나이브 베이지안의 근본적 한계이다.

## BoW(Bag of Words)
단어별로 index가 부여되어 있을 때 한 문장 또는 한 문서에 대한 벡터를 표현하는 기법이다.
- 하나의 단어를 벡터화 시킬 때는 원핫인코딩 기법을 사용한다.

<img width="269" alt="image" src="https://github.com/user-attachments/assets/ada1a0c0-20bc-4499-9790-0668252a78df">

전체 문서에 있는 모든 단어들에 이미 index가 부여되어 있고 출현한 단어에 대해서만 단어의 개수를 벡터로 표현한다.

<img width="603" alt="image" src="https://github.com/user-attachments/assets/cc123a9d-4ebc-4729-98bf-db3a4d0f5239">

## 베이지안 분류기의 종류
### 베르누이 나이브 베이지안 분류기(BernoulliNB)
다루고자 하는 모든 데이터가 boolean 피쳐이다.

사용되는 데이터 타입은 이산형인데, 이러한 데이터를 모두 boolean 타입으로 변경하여 학습한다.
- 정수 타입 숫자라면 임계값 기준으로 true or false로 변환한다.

### 다항 나이브 베이지안 분류기(MultinomialNB)
베르누이 분류기와 달리 각 피쳐들이 이산형이지만, 이진값이 아닌 여러 개의 값을 가질 수 있다.

<img width="389" alt="image" src="https://github.com/user-attachments/assets/1f0537c1-2a2b-4279-a973-1f51306895ae">

<br/>

<img width="616" alt="image" src="https://github.com/user-attachments/assets/2b2f91a1-50c8-48f6-9a3f-0cd5edfb613f">

#### 다항 나이브 베이지안 분류기 구현하기

<img width="507" alt="image" src="https://github.com/user-attachments/assets/a22284db-8296-4b45-974f-8ac64f270bcf">

### 가우시안 나이브 베이지안 분류기(GaussianNB)
연속형 값을 피쳐로 가진 데이터의 확률을 구하기 위해 y의 분포를 정규분포(gaussian)로 가정한다.
- 확률밀도 함수 상의 해당 값 x가 나올 확률로 나이브 베이지안(NB)을 구현한다.
- 가능도는 아래처럼 쓴다.

<img width="284" alt="image" src="https://github.com/user-attachments/assets/cc8167ca-802f-4d78-b440-6c77a0698069">

## 나이브 베이지안 분류기 구현하기

<img width="507" alt="image" src="https://github.com/user-attachments/assets/07e5da86-dd18-4a4e-b6a8-a15ca1bc9916">

<br/>

<img width="477" alt="image" src="https://github.com/user-attachments/assets/c0109c92-0567-4fad-8be8-a51313162335">

새로운 값이 입력되면 다음 수식과 같이 성별을 구분한다.
- postertior(male) = P(male)P(height | male)P(weight | male)P(foot size | male) / evidence
- postertior(female) = P(female)P(height | female)P(weight | female)P(foot size | female) / evidence
