# 로지스틱 회귀
## 분류(Classification) 문제
몇 가지 이산적 값 중 하나를 선택하는 모델로 '분류 모델'이라고 부른다.

분류와 군집(clustering)의 차이는 무엇일까?

아래 표는 GRE와 GPA 데이터를 통해 대학의 합격 여부(Admit 열)을 나타낸다.

<img width="344" alt="image" src="https://github.com/user-attachments/assets/ba149526-9f67-4098-b967-619f9bbc9bb7">

### 선형 회귀로 풀어본다면?
GRE와 GPA 정보를 산점도로 표현해보자.
- 합격자는 파란색, 불합격자는 빨간색으로 나타낸다.
- 초록색 선을 추가해 선 상단은 합격, 선 하단은 불합격이라 생각해보자.

<img width="342" alt="image" src="https://github.com/user-attachments/assets/c07d826f-2fd4-4496-9d7e-0c80a1554a39">

### 선형 회귀 분류기
아래 수식으로 기존 선형회귀 모델을 적용해보자.

<img width="333" alt="image" src="https://github.com/user-attachments/assets/fc45919f-a98b-4a0e-b12b-a6bc777d6f86">

아래와 같은 문제점이 발생한다.
- f(x)가 1 이상이나 0 이하로 나올 수 있다.
- 각 feature들이 Y에 영향을 주는 정도를 해석하기 어렵다.
- 사건의 발생 여부는 이산적이지만 f(x)는 연속적이다.

로지스틱 회귀로 '분류' 문제를 풀어보자.

## 분류 예시
- 이메일이 스팸 메일이냐 아니냐
- 온라인 송금이 사기냐 아니냐
- 종양이 악성종양이냐 아니냐

위와 같은 경우를 이진 분류(binary classification)이라고 한다.
- y ∈ {0, 1}
- 0은 negative class(양성 종양)이다.
- 1은 positive class(악성 종양)이다.

## 로지스틱 회귀란?
이진 분류(binary classification) 문제를 확률로 표현한다.

어떤 사건이 일어날 확률을 P(X)로 나타내고 일어나지 않을 확률을 1 - P(X)로 나타내보자.(0 <= P(X) <= 1)

오즈비(odds ratio)란 어떤 사건이 일어날 확률과 일어나지 않을 확률의 비율을 말한다.

<img width="100" alt="image" src="https://github.com/user-attachments/assets/399bd255-8317-4b33-8c06-d82626356c33">

## Odds Ratio
확률이 올라갈수록 오즈비도 급속히 상승한다.

<img width="430" alt="image" src="https://github.com/user-attachments/assets/aeac9b27-0421-4440-8ece-7bae2413ab01">

## 로지스틱 회귀란?
### 로짓(Logit) 함수
odds ratio에 상용로그를 붙인 수식이다.

<img width="644" alt="image" src="https://github.com/user-attachments/assets/d780b071-cb53-481c-a151-538a68a873db">

X 값으로 확률을 넣으면 logit(P) 꼴로 나타난다.

확률을 구하려면 기존 함수의 역함수를 취하여 연산한다.

<img width="446" alt="image" src="https://github.com/user-attachments/assets/edda52a8-416d-469a-b1eb-c5e3ed4ad46a">

### 로지스틱 함수(Logistic Function)
로짓 함수의 역함수이다.

그래프가 S자 커브 형태인 시그모드이 함수(sigmoid function)이다.

### 시그모이드 함수
S자형 곡선 또는 시그모이드 곡선을 갖는 함수이다.

로지스틱 함수, 쌍곡탄젠트, 아크탄젠트, 오차함수 등이 있다.

### 로지스틱 회귀(Logistic Regression)
종속변수가 이분형일 때 수행할 수 있는, 예측 분석을 위한 회귀분석 기법이다.

시그모이드 함수 수식은 아래와 같다.
- y 값을 확률 p로 표현한다.
- z 값은 선형회귀와 같이 가중치와 피쳐의 선형 결합(linear combination)으로 표현 가능하다.

<img width="335" alt="image" src="https://github.com/user-attachments/assets/ba891362-d467-4d8a-abaa-837a96d41270">

## 로지스틱 회귀의 기본 함수들
### 가설함수(Hypothesis Function)
z는 가중치 값과 피쳐 값의 선형 결합이다.

가중치 값을 찾는 학습을 위해 경사하강법 알고리즘을 사용한다.

<img width="467" alt="image" src="https://github.com/user-attachments/assets/b0a989e4-c3ef-4117-8d43-7fc5bce04d0b">

## 악성 vs 양성 종양
아래같은 상황이라면, "확률"을 학습할 수 있다.
- 만약 h<sub>θ</sub>(x) >= 0.5라면 y = 1(true)
- 만약 h<sub>θ</sub>(x) < 0.5라면 y = 0(false)

<img width="503" alt="image" src="https://github.com/user-attachments/assets/d247d7d5-ad76-46f0-9fcc-945528c5a9b8">

## 로지스틱 회귀의 목적
확률화를 하고 싶다.
- 0 <= h<sub>θ</sub>(x) <= 1
- h<sub>θ</sub>(x) = θ<sup>T</sup>x

어떤 함수를 써야 할까?
- 로지스틱 함수(logistic function)
- 시그모이드 함수(sigmoid function)

## 가설 출력의 해석방법
h<sub>θ</sub>(x)
- x라는 입력이 들어왔을 때 y = 1일 확률이다.

### 예
<img width="615" alt="image" src="https://github.com/user-attachments/assets/c6760917-4dad-4510-a507-9240b01cfe8a">

## 결정 경계(Decision Boundary)
y = 0과 y = 1을 가르는 경계선을 의미한다.

<img width="279" alt="image" src="https://github.com/user-attachments/assets/3dea5755-6aae-43b7-9917-9eda43c9ebc7">

최적 파라미터는 -3 + x<sub>1</sub> + x<sub>2</sub> >= 0이면 y = 1이라고 예측한다.

<img width="163" alt="image" src="https://github.com/user-attachments/assets/55575996-9a22-438d-83a4-6c5887199b95">

비선형적이라면 어떨까?

<img width="398" alt="image" src="https://github.com/user-attachments/assets/c3d8c720-60d3-4bca-880b-264f2e3299d4">

최적 파라미터는 -1 + x<sub>1</sub><sup>2</sup> + x<sub>2</sub><sup>2</sup> >= 0이면 y = 1이라고 예측한다.

<img width="188" alt="image" src="https://github.com/user-attachments/assets/594e10bd-2515-41ad-a085-00b8359e4445">

일반화 해보자.

<img width="652" alt="image" src="https://github.com/user-attachments/assets/c7e631f4-af80-4a55-bf5c-313a78df787c">

## 로지스틱 회귀의 비용 함수
선형 회귀의 비용 함수를 생각해보자.

<img width="310" alt="image" src="https://github.com/user-attachments/assets/4be70db2-d897-4bf1-88b7-424b41e4052b">

이 함수는 명백하게 볼록 함수(convex function)이다.
- 임의의 두 점을 이은 할선이 두 점을 이은 곡선보다 위에 있는 함수이다.
- f(tx<sub>1</sub> + (1 - t)x<sub>2</sub>) <= tf(x<sub>1</sub>) + (1 - t)f(x<sub>2</sub>)
  - 극소값이 명확하게 존재한다.
 
<img width="303" alt="image" src="https://github.com/user-attachments/assets/2e319c79-1f46-4436-810f-d6edae4029cb">

<br>

<img width="549" alt="image" src="https://github.com/user-attachments/assets/56c220b0-7fab-49f0-aca3-c9853ae340f5">

문제는 이 함수가 non - convex function이라는 것이다.
- local minima가 존재할 수 있다.
- 그래서 cost function을 다르게 설계한다.

실제값이 1일 때와 실제값이 0일 때 각각 다르게 비용함수를 정의한다.

<img width="353" alt="image" src="https://github.com/user-attachments/assets/7d217036-9523-4cd1-9e46-5ef2457cee4a">

<br>

<img width="234" alt="image" src="https://github.com/user-attachments/assets/dc01c511-545d-469f-aa43-9750c7d1931f">

### y = 1인 경우
<img width="403" alt="image" src="https://github.com/user-attachments/assets/c57a313f-3a65-4d7b-9bb5-0dde1d4333db">

### y = 0인 경우
<img width="413" alt="image" src="https://github.com/user-attachments/assets/7b60f820-b9f8-4549-b2c2-5b8745727927">

## 비용함수의 단순화
두 경우의 비용함수를 하나로 통합한다.(y는 항상 0이거나 1이다.)

<img width="496" alt="image" src="https://github.com/user-attachments/assets/80a2cb25-b10f-450a-8347-c1c0ef1536f0">

파라미터 θ를 fitting하려면

<img width="85" alt="image" src="https://github.com/user-attachments/assets/61235173-41dd-4af3-afee-e670e05092a7">

새로운 x에 대해서는

<img width="184" alt="image" src="https://github.com/user-attachments/assets/ba2f8603-8dac-43ab-922a-60e514fe6d14">

## 경사하강법
<img width="593" alt="image" src="https://github.com/user-attachments/assets/80e8bb53-c7f2-4af9-9f68-b53aabbbb5aa">

## 분류 문제의 성능지표
모델을 평가하는 성능지표들은 아래와 같다.
- 회귀(regression)
  - MAE, MSE, RMSE, SSE
 
- 분류(classification)
  - 정확도, 정밀도, 민감도, F1 스코어, ROC 커브, 리프트 차트
 
- 클러스터링(clustering)
  - DBI, 엘보우 메소드, 실루엣계수
 
성능 지표가 정답을 주지는 않는다.

앞에서 소개한 기초 성능지표 외에도 실제 머신러닝을 적용한 시스템에서 사용가능한 다양한 추가 성능지표들이 있다.

이때 다음과 같은 여러 가지 상황을 고려하여 모델의 성능지표를 선택해야 한다.
- 모델이 다른 모델보다 경제적으로 나은가?
- 모델이 사용하는 데이터가 많은가? 또는 적은가?
- 모델이 용량이 작은 컴퓨터에서도 작동하는가?
- 모델의 손해가 얼마나 나는가?

## 혼동 행렬(Confusion Matrix)
예측값이 실제값 대비 얼마나 잘 맞는지 2 x 2 행렬로 표현한 것이다.
- 일반적으로 질문의 '예'에 해당하는 값은 true 또는 1, '아니오'에 해당하는 값은 false 또는 0

<img width="400" alt="image" src="https://github.com/user-attachments/assets/0a3dba7f-df49-4136-aff3-6ab855eb389e">

## 분류 문제의 성능지표
실제값과 예측값의 조합으로 발생 가능한 경우는 아래 4가지이다.
- True Positive(TP)
  - 예측값과 실제값이 모두 1로 동일할 때
  - 즉 모델의 예측값이 정답이고 예측 대상이 1일 때
 
- True Negative(TN)
  - 예측값과 실제값이 모두 0으로 동일할 때
  - 즉 모델의 예측값이 정답이고 예측 대상이 0일 때
 
- False Negative(FN)
  - 실제값은 1이지만 예측값이 0
  - 모델의 예측값이 오답이고 예측값이 0을 예측할 때
 
- False Positive(FP)
  - 실제값은 0이지만 예측값이 1
  - 모델의 예측값이 오답이고 예측값이 1을 예측할 때
 
## 혼돈행렬을 사용한 지표
### 정확도(Accuracy)
전체 데이터 개수 대비 정답을 맞춘 데이터의 개수

<img width="328" alt="image" src="https://github.com/user-attachments/assets/3fcf5398-ed15-4907-ad95-ca0c585e080b">

### 정밀도, 민감도, F1 스코어
정밀도와 민감도는 불균일한 데이터셋을 다룰 때 유용하다.
- 데이터에서 1과 0의 비율이 7 : 3 또는 3 : 7 이상 차이나는 상태를 말한다.

### 정밀도(Precision)
모델이 1이라고 예측했을 때 얼마나 잘 맞을지에 대한 비율

<img width="616" alt="image" src="https://github.com/user-attachments/assets/4020aa38-c7f3-4309-8b2d-0ceef83521ce">

### 민감도(Recall)
실제 1인 값을 가진 데이터를 모델이 얼마나 1이라고 잘 예측했는지에 대한 비율이다.
- 반환율 또는 재현율이라고도 부른다.

<img width="301" alt="image" src="https://github.com/user-attachments/assets/b8f221b3-5429-46d6-b86b-9196fb846bc5">
