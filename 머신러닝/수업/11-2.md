# 로지스틱 회귀
## Softmax 함수
softmax 함수는 아래와 같이 구현할 수 있다.

$\sigma(z_j) = \frac{exp(z_j)}{\sum_k exp(z_k)}$

```
import numpy as np

def softmax(values):
    array_values = np.exp(values)
    return array_values / np.sum(array_values)

values = [2, 1, 5, 0.5]
y = softmax(values) # array([0.04613281, 0.01697131, 0.92660226, 0.01029362])
y.sum()

"""
결과
1.0
"""
```

## MNIST 다루기
Modified National Institute of Standards and Technology database로 손으로 쓴 숫자들로 이루어진 데이터이다.

### 데이터 불러오기
`datasets` 모듈을 호출하고 `load_digits` 함수로 딕셔너리 타입 데이터를 불러온다.

```
from sklearn import datasets
digit_dataset = datasets.load_digits()
digit_dataset.keys()

"""
결과
dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])
"""
```

데이터의 형태를 보자.

```
digit_dataset["images"].shape

digit_dataset["target"][0]

digit_dataset["images"][0]

"""
결과
(1797, 8, 8)

0

array([[ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.],
       [ 0.,  0., 13., 15., 10., 15.,  5.,  0.],
       [ 0.,  3., 15.,  2.,  0., 11.,  8.,  0.],
       [ 0.,  4., 12.,  0.,  0.,  8.,  8.,  0.],
       [ 0.,  5.,  8.,  0.,  0.,  9.,  8.,  0.],
       [ 0.,  4., 11.,  0.,  1., 12.,  7.,  0.],
       [ 0.,  2., 14.,  5., 10., 12.,  0.,  0.],
       [ 0.,  0.,  6., 13., 10.,  0.,  0.,  0.]])
"""
```

```
import matplotlib.pyplot as plt
from random import randint
_, axes = plt.subplots(nrows=1, ncols=4, figsize=(10, 3))  # (1)

for ax in axes:  # (2)
    num = randint(1, 1000)  # (3)
    image = digit_dataset["images"][num]
    label = digit_dataset["target"][num]    
    ax.set_axis_off()
    ax.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')  # (4)
    ax.set_title('Training: %i' % label)
```

<img width="581" alt="image" src="https://github.com/user-attachments/assets/17d2a8db-d289-4c66-8015-e452a7423634">

```
# 데이터가 8×8 행렬이므로 2D 이미지로 표현되었지만
# 다음 코드와 같이 총 64개의 피쳐(feature)를 가진 하나의 데이터로 쓸 수 있다.
digit_dataset["data"][0].shape

digit_dataset["data"][0]

# 이는 아래와 동등합니다.
digit_dataset["images"][0].reshape(-1)

"""
결과
(64,)

array([ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.,  0.,  0., 13., 15., 10.,
       15.,  5.,  0.,  0.,  3., 15.,  2.,  0., 11.,  8.,  0.,  0.,  4.,
       12.,  0.,  0.,  8.,  8.,  0.,  0.,  5.,  8.,  0.,  0.,  9.,  8.,
        0.,  0.,  4., 11.,  0.,  1., 12.,  7.,  0.,  0.,  2., 14.,  5.,
       10., 12.,  0.,  0.,  0.,  0.,  6., 13., 10.,  0.,  0.,  0.])

array([ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.,  0.,  0., 13., 15., 10.,
       15.,  5.,  0.,  0.,  3., 15.,  2.,  0., 11.,  8.,  0.,  0.,  4.,
       12.,  0.,  0.,  8.,  8.,  0.,  0.,  5.,  8.,  0.,  0.,  9.,  8.,
        0.,  0.,  4., 11.,  0.,  1., 12.,  7.,  0.,  0.,  2., 14.,  5.,
       10., 12.,  0.,  0.,  0.,  0.,  6., 13., 10.,  0.,  0.,  0.])
"""
```

### 데이터 전처리
이미 잘 처리된 데이터니 `train_test_split` 정도만 해주면 된다.

```
from sklearn.model_selection import train_test_split

X = digit_dataset["data"]   # (1)
y = digit_dataset["target"]   # (1)
X_train, X_test, y_train, y_test = train_test_split(X, y)   # (2)
```

### 모델 만들기
#### Ovr
클래스 모드를 모두 이진모델로 만들어 학습한다.(one - vs - rest)
- 각 클래스에 대해 하나의 로지스틱 회귀 모델을 학습하고, 해당 클래스를 positive 클래스로, 다른 모든 클래스를 negative 클래스로 학습한다.
- 각 클래스의 확률을 예측하고 가장 높은 확률을 가진 클래스를 예측 클래스로 선택한다.

#### Multinomial
softmax 함수를 사용하여 계산하는 방식으로 경사하강법의 매개변수 solver를 sag으로 변경한다.
- 각 클래스의 확률을 예측하고 가장 높은 확률을 가진 클래스를 예측 클래스로 선택한다.

```
from sklearn.linear_model import LogisticRegression

logreg_ovr = LogisticRegression(multi_class="ovr", max_iter=1000)
logreg_softmax = LogisticRegression(multi_class="multinomial", solver="sag", max_iter=1000)

logreg_ovr.fit(X_train, y_train)
logreg_softmax.fit(X_train, y_train)
```

### 성능 측정하기
일반적으로 다중클래스 분류도 혼동행렬을 쓸 수 있다.

실제 클래스와 예측한 값을 행렬 형태로 표현하면 된다.

```
from sklearn.metrics import confusion_matrix
y_pred = logreg_ovr.predict(X_test).copy()
y_true = y_test.copy()
confusion_matrix(y_true, y_pred)

"""
결과
array([[48,  0,  0,  0,  0,  0,  0,  0,  0,  0],
       [ 0, 39,  0,  1,  0,  0,  1,  0,  1,  0],
       [ 0,  1, 49,  0,  0,  0,  0,  0,  0,  0],
       [ 0,  0,  0, 43,  0,  0,  0,  0,  3,  0],
       [ 0,  0,  0,  0, 37,  0,  0,  0,  0,  0],
       [ 0,  1,  0,  0,  0, 48,  0,  0,  0,  2],
       [ 0,  1,  0,  0,  0,  0, 37,  0,  0,  0],
       [ 0,  0,  0,  0,  0,  0,  0, 45,  0,  1],
       [ 0,  5,  1,  0,  0,  0,  0,  0, 48,  0],
       [ 1,  1,  0,  0,  0,  0,  0,  0,  1, 35]])
"""
```

```
from sklearn.metrics import ConfusionMatrixDisplay

confumat = ConfusionMatrixDisplay(confusion_matrix(y_true, y_pred))
confumat.plot()
```

<img width="579" alt="image" src="https://github.com/user-attachments/assets/7c387e95-abca-4ce5-a88d-3e3d9988f12c">

클래스별로 분류 성능을 수치화해서 보려면 `sklearn.metrics.classification_report`를 사용하면 된다.

```
from sklearn.metrics import classification_report
print(classification_report(y_true, y_pred))

"""
결과
              precision    recall  f1-score   support

           0       0.98      0.98      0.98        54
           1       0.98      0.98      0.98        52
           2       1.00      0.98      0.99        47
           3       0.97      0.88      0.92        34
           4       0.97      0.97      0.97        36
           5       0.94      0.98      0.96        45
           6       1.00      1.00      1.00        45
           7       0.95      0.93      0.94        41
           8       0.87      0.98      0.92        46
           9       0.98      0.92      0.95        50

    accuracy                           0.96       450
   macro avg       0.96      0.96      0.96       450
weighted avg       0.96      0.96      0.96       450
"""
```

다중 분류는 평균적인 분류율로 가지고 성능을 논할 때가 많다.

크게는 macro average와 micro average로 나눈다.

#### Macro Average
각 클래스별로 지표를 계산한 후 평균을 낸다.

모든 클래스에 동일한 가중치를 부여한다.

클래스 불균형이 있을 때도 각 클래스를 동등하게 취급한다.

(클래스1_지표 + 클래스2_지표 + ... + 클래스N_지표) / N

#### Micro Average
전체 데이터에 대해 한 번에 지표를 계산한다.

각 샘플에 동일한 가중치를 부여한다.

클래스 불균형이 있을 때 더 많은 샘플을 가진 클래스에 높은 가중치를 부여한다.

데이터를 하나로 모아서 계산하므로 클래스 크기의 영향을 받는다.

전체 중 맞은 개수 / 전체 데이터 개수

#### 클래스가 균형적일 때
macro와 micro average가 비슷한 값을 보인다.
- 어떤 것을 사용해도 무방하다.

MNIST가 이런 케이스이다.

#### 클래스가 불균형적일 떄
macro average는 소수 클래스의 성능도 중요할 때 사용한다.

micro average는 다수 클래스의 성능이 중요할 때 사용한다.

```
result = confusion_matrix(y_true, y_pred)
result.diagonal().sum() / result.sum(axis=0).sum()

from sklearn.metrics import precision_score
precision_score(y_true, y_pred, average="micro")

precision_score(y_true, y_pred, average="macro")

precision_score(y_true, y_pred, average=None) # 이건 클래스별로 따로 보여준다.

precision_score(y_true, y_pred, average=None).mean() # 이 값이 macro average와 같아진다.

"""
결과
0.9533333333333334

0.9533333333333334

0.9549761783471175

array([0.97959184, 0.8125    , 0.98      , 0.97727273, 1.        ,
       1.        , 0.97368421, 1.        , 0.90566038, 0.92105263])

0.9549761783471175
"""
```

## ROC Curve
TPR(True Positive Rate)과 FPR(False Positive Rate)을 각각 y축, x축에 나타내어 그래프를 그린다.

### 구현하기
정답 y 값과 각 항목별 예측 확률을 scores에 저장한다.

ROC 커브 함수인 `roc_curve`로 FPR, TPR, thresholds를 반환한다.

```
import numpy as np
from sklearn import metrics

y = np.array([1, 1, 2, 2])
scores = np.array([0.1, 0.4, 0.35, 0.8])
fpr, tpr, thresholds = metrics.roc_curve(y, scores, pos_label=2)

# fpr - array([0. , 0. , 0.5, 0.5, 1. ])
# tpr - array([0. , 0.5, 0.5, 1. , 1. ])
# thresholds - array([1.8 , 0.8 , 0.4 , 0.35, 0.1 ])

y = np.array([1, 1, 2, 2])
pred = np.array([0.1, 0.4, 0.35, 0.8])
fpr, tpr, thresholds = metrics.roc_curve(y, pred, pos_label=2)
roc_auc = metrics.auc(fpr, tpr)
roc_auc

"""
결과
0.75
"""
```

```
import matplotlib.pyplot as plt

plt.figure()
lw = 2
plt.plot(fpr, tpr, 
         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver operating characteristic example')
plt.legend(loc="lower right")
plt.show()
```

<img width="584" alt="image" src="https://github.com/user-attachments/assets/85a012d0-a361-4d1a-860e-d40df1b0168d">

`sklearn.datasets.make_classificaiton`은 가상의 분류 데이터를 만들어준다.

아래 가상 데이터로 만든 코드를 한 번 보자.

```
import numpy as np
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import roc_curve, auc
import matplotlib.pyplot as plt

# 샘플 데이터 생성
X, y = make_classification(
    n_samples=1000,  # 샘플 개수
    n_classes=2,     # 이진 분류
    n_features=20,   # 특성 개수
    n_informative=15,# 정보를 가진 특성 개수
    random_state=42
)

# 학습/테스트 데이터 분리
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)

# 로지스틱 회귀 모델 학습
model = LogisticRegression()
model.fit(X_train, y_train)

# 예측 확률 계산
y_pred_proba = model.predict_proba(X_test)[:, 1]

# ROC 커브 계산
fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)
roc_auc = auc(fpr, tpr)

# ROC 커브 시각화
plt.figure(figsize=(10, 6))
plt.plot(fpr, tpr, color='darkorange', lw=2, 
         label=f'ROC curve (AUROC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', 
         label='Random classifier')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate (1 - Specificity)')
plt.ylabel('True Positive Rate (Sensitivity)')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.grid(True)

# 임계값 표시 (0.3, 0.5, 0.7)
threshold_points = [0.3, 0.5, 0.7]
for threshold in threshold_points:
    # 가장 가까운 임계값 찾기
    idx = np.argmin(np.abs(thresholds - threshold))
    plt.plot(fpr[idx], tpr[idx], 'ro')
    plt.annotate(f'threshold={threshold:.1f}', 
                (fpr[idx], tpr[idx]), 
                xytext=(10, 10), 
                textcoords='offset points')

plt.show()

# 주요 임계값들에 대한 성능 지표 출력
print("\n임계값별 성능 지표:")
print("Threshold | False Positive Rate | True Positive Rate")
print("-" * 50)
for threshold in threshold_points:
    idx = np.argmin(np.abs(thresholds - threshold))
    print(f"{threshold:.1f}       | {fpr[idx]:.3f}              | {tpr[idx]:.3f}")
```

<img width="600" alt="image" src="https://github.com/user-attachments/assets/8b0f1650-33ea-42ce-9d27-f0b2b0ede702">
