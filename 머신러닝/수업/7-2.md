# 선형회귀 기초
## SST, SSE, SSR and R ^ 2
δ ^ 2값은 fitted value의 범위에 따라 달라지므로, test에는 적합하지 않다.
- 다른 값을 정의해보자.

H0 : ß1 = 0을 가정해보자.
- 이 가정읕 통해 total sum of squares(SST)라는 값을 정의 가능하다.

<img width="226" alt="image" src="https://github.com/user-attachments/assets/904e3394-e5a0-4c60-9d32-eeb38881a69c">

- SST는 SSE와 SSR이라는 값의 합으로 이해 가능하다.

<img width="122" alt="image" src="https://github.com/user-attachments/assets/0ff2954a-09cd-4701-b5a0-5dedd08a9016">

## Extrapolation의 위험성
데이터상의 독립변수 x의 범위를 벗어나는 경우를 보는 경우를 외삽(extrapolation)이라고 한다.
- 이 경우 부정확한 결과를 얻을 수 있으므로 주의해야 한다.

## Error Variance δ ^ 2
마지막으로 남은 parameter는 error variance δ ^ 2이다.
- 이 값은 데이터의 yi와 fitted values yi의 차이를 통해 구할 수 있다.

sum of squares for error(SSE)라는 값을 아래와 같이 정의한다.

<img width="398" alt="image" src="https://github.com/user-attachments/assets/376c1db8-8bf8-4167-8677-12f8b2675929">

- 위의 값을 통해 error variance의 estimate는 아래와 같이 구할 수 있다.

<img width="58" alt="image" src="https://github.com/user-attachments/assets/c9088e19-fd07-4f0f-8ea3-3404bf58ea54">

- 이 값이 너무 크면 좋은 fitting이 아니다.

## 정리
<img width="474" alt="image" src="https://github.com/user-attachments/assets/fd075f0d-14f5-4ba1-ad7a-84e0fdec0b3d">

즉, 계산 측면에서는 아래의 6가지 값을 구하면 된다.

<img width="249" alt="image" src="https://github.com/user-attachments/assets/6cc665e2-06b3-4729-a476-e14e22790e22">

## 예 : 자동차 공장의 전기 사용량
공장장이 공장의 효율을 확인하기 위해서 매 달 생산한 자동차의 총 가격과 전기 소모량을 비교하고자 한다.

이 경우 선형 모델(y = ß0 + ß1x)을 통해 전기 사용량을 생산된 자동차 총 가격의 함수로 표현할 수 있다.

<img width="326" alt="image" src="https://github.com/user-attachments/assets/b972af1c-274f-4b80-a917-e00f8295932d">

- n = 12
- ∑(i = 1 ~ 12)xi = 4.51 + ... + 4.20 = 58.62
- ∑(i = 1 ~ 12)yi = 2.48 + ... + 2.53 = 34.15
- ∑(i = 1 ~ 12)xi ^ 2 = 4.51 ^ 2 + ... + 4.20 ^ 2 = 291.2310
- ∑(i = 1 ~ 12)yi ^ 2 = 2.48 ^ 2 + ... + 2.53 ^ 2 = 98.6967
- ∑(i = 1 ~ 12)xiyi = (4.51 x 2.48) + ... + (4.20 x 2.53) = 169.2532

값을 대입하면 아래와 같다.

<img width="658" alt="image" src="https://github.com/user-attachments/assets/6fc0d469-fb37-43ba-ba8f-904830991b83">

<img width="568" alt="image" src="https://github.com/user-attachments/assets/8f86908c-d4c1-4bf1-8430-68adb1af39d2">

## 선형회귀 성능 측정하기
### 모델이 데이터에 과다적합(Over - Fit)된 경우
생성된 모델이 특정 데이터에만 잘 맞아서 해당 데이터셋에 대해서는 성능을 발휘할 수 있지만 새로운 데이터셋에서는 전혀 성능을 낼 수 없다.
- 일반화 성능이 없다.

### 모델이 데이터에 과소적합(Under - Fit)된 경우
기존 학습 데이터를 제대로 예측하지 못한다.

### 홀드아웃 메서드(Hold - Out Method)
전체 데이터셋에서 일부를 학습 데이터와 테스트 데이터로 나누는 일반적인 데이터 분할 기법이다.
- 전체 데이터에서 랜덤하게 학습 데이터셋과 테스트 데이터셋으로 나눈다.
- 일반적으로 7 : 3 또는 8 : 2 정도의 비율로 나눈다.(데이터가 커지면 9 : 1 비율도 가능하다.)

<img width="423" alt="image" src="https://github.com/user-attachments/assets/6064d9cc-e270-4d2d-8583-6d2378dbd985">

## 선형회귀의 성능 측정 지표
### MAE(Mean Absolute Error) : 평균 절대 잔차
모든 테스트 데이터에 대해 예측값과 실제값의 차이에 대해 절대값을 구하고, 이 값을 모두 더한 후에 데이터의 개수만큼 나눈 결과이다.

직관적으로 예측값과 실측값의 차이를 알 수 있다.

<img width="270" alt="image" src="https://github.com/user-attachments/assets/8240927f-dbb1-408a-b4a6-2c1b29ef8a4c">

### RMSE(Root Mean Squared Error) : 평균제곱근 오차
오차에 대해 제곱을 한 다음 모든 값을 더하여 평균을 낸 후 제곱근을 구한다.

MAE에 비해 상대적으로 값의 차이가 더 크다.

차이가 크게 나는 값에 대해서 페널티를 주고 싶다면 RMSE 값을 사용한다.

<img width="257" alt="image" src="https://github.com/user-attachments/assets/2694b1d7-4ac3-47b9-9e5a-65a7489e5784">

### 결정계수(R - Squared) : 두 개의 값의 증감이 얼마나 일관성을 가지는지 나타내는 지표
예측값이 크면 클수록 실제값도 커지고, 예측값이 작으면 실제값도 작아진다.

두 개의 모델 중 어떤 모델이 조금 더 상관성이 있는지를 나타낼 수 있지만, 값의 차이 정도가 얼마인지를 나타낼 수 없다는 한계가 있다.

<img width="211" alt="image" src="https://github.com/user-attachments/assets/17901e4f-e1f5-43e9-a4b4-c0a533741266">

## SST, SSE, SSR
각각은 아래와 같은 의미를 가진다.

<img width="638" alt="image" src="https://github.com/user-attachments/assets/36792694-8ddf-44f3-88da-91b57b495fd7">

## SST, SSE, SSR and R ^ 2
SSE와 SSR의 제곱의 평균(mean square)은 아래와 같다.

<img width="203" alt="image" src="https://github.com/user-attachments/assets/9ba4ed00-2225-4a06-aa3f-1d1f78dc0424">

이 두 가지의 비율은 F - distribution을 따른다.(F - statistic)

<img width="140" alt="image" src="https://github.com/user-attachments/assets/75ecc6e4-64eb-482e-b3a8-978166e13bb6">

two - sided p - value는 F 분포를 통해 구할 수 있다.
- p - value = p(X > F)

coefficient of determination은 아래와 같이 정의된다.

<img width="252" alt="image" src="https://github.com/user-attachments/assets/4aab9595-7806-45bd-8a8c-8ad839bd727f">

- 이 값이 작을수록 좋은 fitting일 가능성이 높다.

<img width="339" alt="image" src="https://github.com/user-attachments/assets/67ffdaca-0569-46b6-93c6-71e44158aa7d">

## R ^ 2와 Pearson Correlation의 관계
<img width="613" alt="image" src="https://github.com/user-attachments/assets/08cd75dd-8539-4e64-8736-01193482ee8f">

# 선형회귀 실습
## 경사하강법 Remind
경사하강법(gradient descent)
- 경사를 하강하면서 수식을 최소화하는 매개변수의 값을 찾아내는 방법이다.
- 점이 최솟값을 달성하는 방향으로 점점 내려간다.
  - 몇 번 적용할 것인가?
    - 많이 실행할수록 최솟값에 가까워지지만 시간이 더 많이 걸린다.
   
  - 한 번에 얼마나 많이 내려갈 것인가?
    - 한 번에 얼마나 많은 공간을 움직일지를 정한다.
   
  - 경사(gradient)
    - 경사하강법의 하이퍼 매개변수
   
## 예
* $f(x) = x^2 \rightarrow \frac{dy}{dx}=2x$ 
* $x_{new} = x_{old} - \alpha \times f'(x_{old})$

```
import numpy as np
import matplotlib.pyplot as plt

x= np.arange(-10,10,0.1)
f_x = x ** 2
# 일단 f(x)를 그려보자.

plt.plot(x, f_x)
plt.show()
```

<img width="573" alt="image" src="https://github.com/user-attachments/assets/a362bbf7-2fa8-4e7f-a78a-ad9163f8486d">

경사만큼 x를 계속 변화시키는 작업을 해보자.

```
x_new = 10
derivative = []
y = []
learng_rate= 0.1
for i in range(100):
    old_value = x_new
    derivative.append(old_value - learng_rate * 2 * old_value)
    x_new = old_value - learng_rate *2* old_value
    y.append(x_new ** 2)

plt.plot(x, f_x)
plt.scatter(derivative, y)
plt.show()
```

<img width="568" alt="image" src="https://github.com/user-attachments/assets/9b1a25b4-5fe3-4c34-995c-a2a1dfcc2584">

### 알 수 있는 내용
평형점(극점)에 다다를수록 기울기가 줄어든다.
- 이는 '미분 가능한' 함수라면 보통 동일한 특성을 가진다.

즉, 상수 learning rate를 가졌더라도 극점 근처가 되면 점점 한 step의 차이가 줄어든다.
- 이는 경사하강법이 정답에 다다를수록 정확한 값을 찾아가게 해주지만(먼 거리에서는 빠르게, 가까운 거리에서는 느리게) 반대로 '진짜 극점'을 찾는 것을 어렵게 한다.

### 성능 측정
#### 훈련 / 테스트 분할(Train / Test Split)
머신러닝에서 데이터를 학습하기 위한 학습 데이터셋(train dataset)과 학습의 결과로 생성된 모델의 성능을 평가하기 위한 테스트 데이터셋(test dataset)으로 나눈다.

모델이 새로운 데이터셋에도 일반화(generalize)하여 처리할 수 있는지를 확인한다.

sklearn 모듈이 제공하는 `train_test_split` 함수가 가장 많이 쓰인다.
- X와 y 벡터 값을 각각 넣는다.
- 매개변수 test_size에 테스트 데이터로 사용할 데이터의 비율을 지정한다.
- random_state는 무작위 난수를 생성하기 위한 seed 값이다.

```
# test - train - valid를 3개 셋으로 분할한다.
import numpy as np
from sklearn.model_selection import train_test_split

X, y = np.arange(10).reshape((5, 2)), range(5)

# 5개의 데이터 중 약 33%인 2개가 테스트 셋으로 설정된다.
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)
```

#### MAE(Mean Abosolute Error) : 평균 절대 잔차
모든 테스트 데이터에 대해 예측값과 실제값의 차이에 대해 절대값을 구하고, 이 값을 모두 더한 후에 데이터의 개수만큼 나눈 결과이다.

직관적으로 예측값과 실측값의 차이를 알 수 있다.

sklearn 모듈에서는 `median_abosolute_error` 함수로 MAE를 구하면 된다.

```
from sklearn.metrics import median_absolute_error
y_true = [3, -0.5, 2, 7]
y_pred = [2.5, 0.0, 2, 8]
median_absolute_error(y_true, y_pred)

"""
결과
0.5
"""
```

#### MSE(Mean Square Error) : 오차에 대해 제곱근을 한 다음 모든 값을 더하여 평균 / RMSE(Root MSE) : MSE의 제곱근
MAE에 비해 먼 점에 대한 패널티가 더 크다.

상대적으로 값이 차이가 더 크다.
- 차이가 크게 나는 값에 대해서 패널티를 주고 싶다면 RMSE 값을 사용한다.

sklearn 모듈에서는 RMSE를 직접적으로 지원하지 않고 `MSE(mean_square_error)`만 지원한다.
```
from sklearn.metrics import mean_squared_error
y_true = [3, -0.5, 2, 7]
y_pred = [2.5, 0.0, 2, 8]
print(mean_squared_error(y_true, y_pred)) # MSE
print(np.sqrt(mean_squared_error(y_true, y_pred))) # RMSE

"""
결과
0.375
0.6123724356957945
"""
```

#### R ^ 2 - Score(결정 계수) : 두 개의 값의 증감이 얼마나 일관성을 가지는지 나타내는 지표
값이 클수록 실제값도 커지고, 예측값이 작으면 실제값도 작아진다.

여러 모델 중 어떤 모델이 조금 더 상관성이 있는지를 나타낼 수 있지만, 값의 차이 정도가 얼마인지를 나타낼 수 없다는 한계가 있다.

```
from sklearn.metrics import r2_score
y_true = [3, -0.5, 2, 7]
y_pred = [2.5, 0.0, 2, 8]
r2_score(y_true, y_pred)

"""
결과
0.9486081370449679
"""
```

## 선형회귀 구현
### 데이터 생성
y = x + 25에 노이즈를 주어 만들어보자.
```
import matplotlib.pyplot as plt
import numpy as np
import random

def gen_data(numPoints, bias, variance):
    x = np.zeros(shape=(numPoints, 2))
    y = np.zeros(shape=numPoints)
    
    for i in range(0, numPoints):
        x[i][0] = 1 # (2) 데이터 x의 상수항에는 1
        x[i][1] = i # (3) 데이터 x 값은 1씩 증가시킴
        y[i] = (i+bias) + random.uniform(0, 1) * variance
        # (4) 데이터 y에 bias 생성
    return x, y

x, y = gen_data(100, 25, 10) # (1) 100개의 데이터 생성

plt.plot(x[:,1]+1,y,"ro") # (5) 데이터 x와 y의 상관관계 그래프 작성
plt.show()
```

<img width="569" alt="image" src="https://github.com/user-attachments/assets/ce03d5f6-e294-47ba-b3d3-32f226304a0a">

### 경사하강법 적용
파라미터가 2개이지만, 각각은 따로 작동할 수 있다.
```
def gradient_descent(x, y, theta, alpha, m, numIterations):
    xTrans = x.transpose() # (6) x 입력값들을 transpose 합니다. x가 현재는 (1, i) 형태로 되어있으므로...
    theta_list = [] # (7) theta 값을 저장할 리스트를 생성해 둡니다.
    cost_list = [] # (8) 비용 값을 저장할 리스트를 생성해 둡니다.
    for i in range(0, numIterations): # (9) 최대 iteration값 만큼 반복 시작
        hypothesis = np.dot(x, theta) # (10) 현재 모델에서 y estimate 값 생성
        loss = hypothesis - y # (11) 예측값과 실제 값 차이를 loss로 저장합시다.
        cost = np.sum(loss ** 2) / (2 * m) # (12) 비용함수를 계산합니다. m은 총 점의 수. 
        gradient = np.dot(xTrans, loss) / m # (13) 편미분 값으로 gradient를 계산합니다. 
        theta = theta - alpha * gradient # (14) 가중치 값인 theta 값이 업데이트 됩니다. 
        if i % 250 == 0: # (15) 250회마다 업데이트 해서 저장합니다. 
            theta_list.append(theta)
        cost_list.append(cost)
    return theta,np.array(theta_list), cost_list # (16)

m, n = np.shape(x) # (1)
numIterations= 5000 # (2)
alpha = 0.0005 # (3)
theta = np.ones(n) # (4)

theta, theta_list, cost_list = gradient_descent(x, y, theta, alpha, m, numIterations) # (5)
```

실제로 어떤 식으로 식이 변하는지 확인해보자.
```
y_predict_step= np.dot(x, theta_list.transpose())
plt.plot(x[:,1],y,"ro")
for i in range (0,20,2):
    plt.plot(x[:,1], y_predict_step[:,i], label='Line %d'%i)
    
plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)
plt.show()
```

<img width="572" alt="image" src="https://github.com/user-attachments/assets/f84b4777-d4c6-42f7-a01d-35895fd15397">

최종적인 값을 확인해보자.
```
y_predict= np.dot(x, theta)
plt.plot(x[:,1],y,"ro")
plt.plot(x[:,1],y_predict, lw=3)
plt.show()
```

<img width="572" alt="image" src="https://github.com/user-attachments/assets/053e443a-8a47-4aec-b244-ee0fc822cf91">

cost가 감소하는 것을 확인해보자.
```
iterations = range(len(cost_list))

plt.scatter(iterations,cost_list)
plt.show()
```

<img width="577" alt="image" src="https://github.com/user-attachments/assets/1d4fc2ab-1afd-4f23-aa79-21c8cecdbe18">

R ^ 2 score가 증가하는 것을 확인해보자.
```
mae_list = []
y_pred_list = np.dot(x, theta_list.transpose()).transpose()
for i in range(len(theta_list)):
    mae_list.append(median_absolute_error(y, y_pred_list[i]))
plt.scatter(np.arange(len(theta_list)), mae_list)
```

<img width="573" alt="image" src="https://github.com/user-attachments/assets/e59d55bb-3c95-45bd-b740-095e63ef3f5a">

```
r2_list = []
for i in range(len(theta_list)):
    r2_list.append(r2_score(y, y_pred_list[i]))
plt.scatter(np.arange(len(theta_list)), r2_list)
```

<img width="581" alt="image" src="https://github.com/user-attachments/assets/97d6524f-f349-4e99-9426-2725f2876dd9">

```
mse_list = []
for i in range(len(theta_list)):
    mse_list.append(mean_squared_error(y, y_pred_list[i]))
plt.scatter(np.arange(len(theta_list)), mse_list)
```

<img width="569" alt="image" src="https://github.com/user-attachments/assets/8330e9b5-c36b-4516-89be-8e50527fe718">
